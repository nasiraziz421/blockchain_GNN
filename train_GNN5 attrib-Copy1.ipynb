{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2273700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "import pickle\n",
    "import torchgeometry as tgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a12780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000to3999999_BlockTransaction.csv  graphs_data  processed.csv\r\n",
      "extracted_labels.csv\t\t       model.pkl    time.csv\r\n",
      "final.csv\t\t\t       model.pt     tx_counts.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../blockchain_files/3000000to3999999_BlockTransaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216dcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "with open(\"../blockchain_files/3000000to3999999_BlockTransaction/graphs_data\", \"rb\") as fp:   # Unpickling\n",
    "    read_graph_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a91db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "count = 0\n",
    "for data in read_graph_data:\n",
    "    \n",
    "    if data.x.shape[0] == 0:\n",
    "        continue\n",
    "        \n",
    "    data_list.append(data)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8aeb353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66a98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_list, batch_size=8,shuffle=True)\n",
    "test_loader = DataLoader(data_list, batch_size=8,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb831af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import BatchNorm1d, Linear\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj, OptTensor, PairTensor\n",
    "\n",
    "\n",
    "class CGConv(MessagePassing):\n",
    "\n",
    "    def __init__(self, channels: Union[int, Tuple[int, int]], dim: int = 0,\n",
    "                 aggr: str = 'mean', batch_norm: bool = False,\n",
    "                 bias: bool = True, **kwargs):\n",
    "        super().__init__(aggr=aggr, **kwargs)\n",
    "        # print(channels)\n",
    "        self.channels = channels\n",
    "        self.dim = dim\n",
    "        self.batch_norm = batch_norm\n",
    "\n",
    "        if isinstance(channels, int):\n",
    "            channels = (channels, channels)\n",
    "        self.lin_f = Linear(2*channels[0] + dim, channels[1], bias=bias)\n",
    "        # self.lin_s = Linear(2*channels[0] + dim, channels[1], bias=bias)\n",
    "        if batch_norm:\n",
    "            self.bn = BatchNorm1d(channels[1])\n",
    "        else:\n",
    "            self.bn = None\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_f.reset_parameters()\n",
    "        # self.lin_s.reset_parameters()\n",
    "        if self.bn is not None:\n",
    "            self.bn.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
    "                edge_attr: OptTensor = None) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        if isinstance(x, Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "\n",
    "        # propagate_type: (x: PairTensor, edge_attr: OptTensor)\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr, size=None)\n",
    "        out = out if self.bn is None else self.bn(out)\n",
    "        out += x[1]\n",
    "        # print(out.shape)\n",
    "        # print(x[1])\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr: OptTensor) -> Tensor:\n",
    "        if edge_attr is None:\n",
    "            z = torch.cat([x_i, x_j], dim=-1)\n",
    "        else:\n",
    "            z = torch.cat([x_i, x_j, edge_attr], dim=-1)\n",
    "\n",
    "        # print(z.shape)\n",
    "        # print(self.lin_f)\n",
    "        return self.lin_f(z)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}({self.channels}, dim={self.dim})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16da6da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): CGConv((1, 64), dim=5)\n",
      "  (conv2): CGConv((64, 64), dim=5)\n",
      "  (conv3): CGConv((64, 64), dim=5)\n",
      "  (conv4): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "#         torch.manual_seed(12345)\n",
    "        self.conv1 = CGConv((1, hidden_channels),5,batch_norm=True)\n",
    "#         self.conv1 = GCNConv(1, hidden_channels)\n",
    "        \n",
    "        self.conv2 = CGConv((hidden_channels, hidden_channels),5,batch_norm=True)\n",
    "        self.conv3 = CGConv((hidden_channels, hidden_channels),5,batch_norm=True)\n",
    "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index,edge_attributes, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index,edge_attributes)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index,edge_attributes)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index,edge_attributes)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    " \n",
    "\n",
    "        # 2. Readout layer\n",
    "#         print(x.shape)\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "#         print(x.shape)\n",
    "        # 3. Apply a final classifier\n",
    "#         x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e6303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# weights = torch.tensor([.05,.95]).to(device)\n",
    "focal_loss = tgm.losses.FocalLoss(alpha=0.5, gamma=2.0, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b88ddcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.lin_f.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c7fc5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "205d0ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    for batch_idx,data in enumerate(train_loader):\n",
    "\n",
    "\n",
    "        data.edge_attr = data.edge_attr.float()\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index,data.edge_attr,data.batch)\n",
    "\n",
    "        loss = focal_loss(out.reshape(-1,2,1,1), data.y.reshape(-1,1,1))   # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "#             print(batch_idx)\n",
    "        \n",
    "\n",
    "    return loss.cpu().item()\n",
    "    \n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        \n",
    "\n",
    "\n",
    "        data.edge_attr = data.edge_attr.float() \n",
    "        data = data.to(device)\n",
    "        \n",
    "        out = model(data.x, data.edge_index,data.edge_attr, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        \n",
    "\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "# test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d25a8d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Acc: 0.7532, loss : 0.0397\n",
      "Epoch: 010, Train Acc: 0.7197, loss : 0.0194\n",
      "Epoch: 015, Train Acc: 0.7277, loss : 0.0316\n",
      "Epoch: 020, Train Acc: 0.7404, loss : 0.0266\n",
      "Epoch: 025, Train Acc: 0.7420, loss : 0.1511\n",
      "Epoch: 030, Train Acc: 0.7325, loss : 0.0132\n",
      "Epoch: 035, Train Acc: 0.7882, loss : 0.0584\n",
      "Epoch: 040, Train Acc: 0.7277, loss : 0.0450\n",
      "Epoch: 045, Train Acc: 0.7771, loss : 0.0446\n",
      "Epoch: 050, Train Acc: 0.7850, loss : 0.1125\n",
      "Epoch: 055, Train Acc: 0.8010, loss : 0.0352\n",
      "Epoch: 060, Train Acc: 0.8280, loss : 0.0421\n",
      "Epoch: 065, Train Acc: 0.7325, loss : 0.0147\n",
      "Epoch: 070, Train Acc: 0.8392, loss : 0.0872\n",
      "Epoch: 075, Train Acc: 0.8519, loss : 0.1577\n",
      "Epoch: 080, Train Acc: 0.7882, loss : 0.0387\n",
      "Epoch: 085, Train Acc: 0.7818, loss : 0.0384\n",
      "Epoch: 090, Train Acc: 0.8710, loss : 0.0210\n",
      "Epoch: 095, Train Acc: 0.8471, loss : 0.0417\n",
      "Epoch: 100, Train Acc: 0.7914, loss : 0.0240\n",
      "Epoch: 105, Train Acc: 0.8089, loss : 0.0344\n",
      "Epoch: 110, Train Acc: 0.8615, loss : 0.0297\n",
      "Epoch: 115, Train Acc: 0.8631, loss : 0.0214\n",
      "Epoch: 120, Train Acc: 0.8933, loss : 0.0236\n",
      "Epoch: 125, Train Acc: 0.8726, loss : 0.0037\n",
      "Epoch: 130, Train Acc: 0.9045, loss : 0.0083\n",
      "Epoch: 135, Train Acc: 0.8838, loss : 0.0537\n",
      "Epoch: 140, Train Acc: 0.8439, loss : 0.0387\n",
      "Epoch: 145, Train Acc: 0.8838, loss : 0.0352\n",
      "Epoch: 150, Train Acc: 0.9029, loss : 0.0299\n",
      "Epoch: 155, Train Acc: 0.9045, loss : 0.0656\n",
      "Epoch: 160, Train Acc: 0.8901, loss : 0.0298\n",
      "Epoch: 165, Train Acc: 0.8424, loss : 0.0084\n",
      "Epoch: 170, Train Acc: 0.8965, loss : 0.0943\n",
      "Epoch: 175, Train Acc: 0.9092, loss : 0.0150\n",
      "Epoch: 180, Train Acc: 0.8822, loss : 0.0771\n",
      "Epoch: 185, Train Acc: 0.8089, loss : 0.0586\n",
      "Epoch: 190, Train Acc: 0.9061, loss : 0.0236\n",
      "Epoch: 195, Train Acc: 0.8965, loss : 0.0245\n",
      "Epoch: 200, Train Acc: 0.9156, loss : 0.1374\n",
      "Epoch: 205, Train Acc: 0.9204, loss : 0.0126\n",
      "Epoch: 210, Train Acc: 0.8567, loss : 0.0145\n",
      "Epoch: 215, Train Acc: 0.8726, loss : 0.1036\n",
      "Epoch: 220, Train Acc: 0.8997, loss : 0.0001\n",
      "Epoch: 225, Train Acc: 0.8694, loss : 0.0363\n",
      "Epoch: 230, Train Acc: 0.9156, loss : 0.0693\n",
      "Epoch: 235, Train Acc: 0.9172, loss : 0.0000\n",
      "Epoch: 240, Train Acc: 0.9220, loss : 0.0326\n",
      "Epoch: 245, Train Acc: 0.8822, loss : 0.0454\n",
      "Epoch: 250, Train Acc: 0.9283, loss : 0.0205\n",
      "Epoch: 255, Train Acc: 0.9108, loss : 0.0114\n",
      "Epoch: 260, Train Acc: 0.9108, loss : 0.0000\n",
      "Epoch: 265, Train Acc: 0.9061, loss : 0.0498\n",
      "Epoch: 270, Train Acc: 0.9236, loss : 0.0240\n",
      "Epoch: 275, Train Acc: 0.9140, loss : 0.0427\n",
      "Epoch: 280, Train Acc: 0.9315, loss : 0.0129\n",
      "Epoch: 285, Train Acc: 0.9220, loss : 0.0006\n",
      "Epoch: 290, Train Acc: 0.8997, loss : 0.0057\n",
      "Epoch: 295, Train Acc: 0.9331, loss : 0.0183\n",
      "Epoch: 300, Train Acc: 0.9156, loss : 0.0305\n",
      "Epoch: 305, Train Acc: 0.9204, loss : 0.0311\n",
      "Epoch: 310, Train Acc: 0.9347, loss : 0.0267\n",
      "Epoch: 315, Train Acc: 0.9315, loss : 0.0117\n",
      "Epoch: 320, Train Acc: 0.9124, loss : 0.0063\n",
      "Epoch: 325, Train Acc: 0.9459, loss : 0.0687\n",
      "Epoch: 330, Train Acc: 0.9490, loss : 0.0141\n",
      "Epoch: 335, Train Acc: 0.9045, loss : 0.0011\n",
      "Epoch: 340, Train Acc: 0.8822, loss : 0.2678\n",
      "Epoch: 345, Train Acc: 0.9363, loss : 0.0487\n",
      "Epoch: 350, Train Acc: 0.9538, loss : 0.0011\n",
      "Epoch: 355, Train Acc: 0.9299, loss : 0.0107\n",
      "Epoch: 360, Train Acc: 0.9172, loss : 0.0019\n",
      "Epoch: 365, Train Acc: 0.9204, loss : 0.0234\n",
      "Epoch: 370, Train Acc: 0.8710, loss : 0.0013\n",
      "Epoch: 375, Train Acc: 0.9108, loss : 0.0646\n",
      "Epoch: 380, Train Acc: 0.9331, loss : 0.0080\n",
      "Epoch: 385, Train Acc: 0.9443, loss : 0.0000\n",
      "Epoch: 390, Train Acc: 0.8997, loss : 0.0058\n",
      "Epoch: 395, Train Acc: 0.9586, loss : 0.0095\n",
      "Epoch: 400, Train Acc: 0.9490, loss : 0.0912\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, 401):\n",
    "    loss = train()\n",
    "#     break\n",
    "    train_acc = test(test_loader)\n",
    "#     test_acc = test(test_loader)\n",
    "    if epoch % 5 == 0: \n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, loss : {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78c45cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6c98bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9490445859872612"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58e65f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22338"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([p.numel() for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fd465f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[12995, 1], edge_index=[2, 17027], edge_attr=[17027, 5], y=[1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_graph_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a02d50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../blockchain_files/4000000to4999999_BlockTransaction/graphs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c64691cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+\"graphs_data_0\", \"rb\") as fp:   # Unpickling\n",
    "    read_graph_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f980ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f948bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data_list = []\n",
    "for name in glob.glob(path+'/*'):\n",
    "#     print(name)\n",
    "    with open(name, \"rb\") as fp:   # Unpickling\n",
    "        read_graph_data = pickle.load(fp)\n",
    "    if read_graph_data.x.shape[0] == 0:\n",
    "        continue\n",
    "    ts_data_list.append(read_graph_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c78c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1405"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ts_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96537f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(ts_data_list, batch_size=2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7636c080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8355871886120997"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b3fb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../blockchain_files/3000000to3999999_BlockTransaction/model.pt'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4318f170",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../blockchain_files/3000000to3999999_BlockTransaction/model.pkl', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(model, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab855439",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../blockchain_files/3000000to3999999_BlockTransaction/model.pkl', \"rb\") as fp:   # Unpickling\n",
    "    model = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53198086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9490445859872612"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf89738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
